{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# f_neuralNetwork_tree_features\r\n",
    "----\r\n",
    "\r\n",
    "Written in the Python 3.7.9 Environment with the following package versions\r\n",
    "\r\n",
    "    * joblib 1.0.1\r\n",
    "    * numpy 1.19.5\r\n",
    "    * pandas 1.3.1\r\n",
    "    * scikit-learn 0.24.2\r\n",
    "    * tensorflow 2.5.0\r\n",
    "\r\n",
    "By Nicole Lund \r\n",
    "\r\n",
    "This Jupyter Notebook tunes a neural network model for Exoplanet classification from Kepler Exoplanet study data.\r\n",
    "\r\n",
    "Column descriptions can be found at https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html \r\n",
    "\r\n",
    "**Source Data**\r\n",
    "\r\n",
    "The source data used was provided by University of Arizona's Data Analytics homework assignment. Their data was derived from https://www.kaggle.com/nasa/kepler-exoplanet-search-results?select=cumulative.csv\r\n",
    "\r\n",
    "The full data set was released by NASA at\r\n",
    "https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/nph-tblView?app=ExoTbls&config=koi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Import Dependencies\r\n",
    "\r\n",
    "# Plotting\r\n",
    "%matplotlib inline\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# Data manipulation\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from statistics import mean\r\n",
    "from operator import itemgetter\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "\r\n",
    "# Parameter Selection\r\n",
    "from sklearn import tree\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "\r\n",
    "# Model Development\r\n",
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.svm import SVC \r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "from tensorflow.keras.layers import Dropout\r\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\r\n",
    "\r\n",
    "# Model Metrics\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "\r\n",
    "# Save/load files\r\n",
    "from tensorflow.keras.models import load_model\r\n",
    "import joblib\r\n",
    "\r\n",
    "# # Ignore deprecation warnings\r\n",
    "# import warnings\r\n",
    "# warnings.simplefilter('ignore', FutureWarning)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Set the seed value for the notebook, so the results are reproducible\r\n",
    "from numpy.random import seed\r\n",
    "seed(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Import data\r\n",
    "df = pd.read_csv(\"../b_source_data/exoplanet_data.csv\")\r\n",
    "# print(df.info())\r\n",
    "\r\n",
    "# Drop columns where all values are null\r\n",
    "df = df.dropna(axis='columns', how='all')\r\n",
    "\r\n",
    "# Drop rows containing null values\r\n",
    "df = df.dropna()\r\n",
    "\r\n",
    "# Display data info\r\n",
    "print(df.info())\r\n",
    "print(df.head())\r\n",
    "print(df.koi_disposition.unique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6991 entries, 0 to 6990\n",
      "Data columns (total 41 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   koi_disposition    6991 non-null   object \n",
      " 1   koi_fpflag_nt      6991 non-null   int64  \n",
      " 2   koi_fpflag_ss      6991 non-null   int64  \n",
      " 3   koi_fpflag_co      6991 non-null   int64  \n",
      " 4   koi_fpflag_ec      6991 non-null   int64  \n",
      " 5   koi_period         6991 non-null   float64\n",
      " 6   koi_period_err1    6991 non-null   float64\n",
      " 7   koi_period_err2    6991 non-null   float64\n",
      " 8   koi_time0bk        6991 non-null   float64\n",
      " 9   koi_time0bk_err1   6991 non-null   float64\n",
      " 10  koi_time0bk_err2   6991 non-null   float64\n",
      " 11  koi_impact         6991 non-null   float64\n",
      " 12  koi_impact_err1    6991 non-null   float64\n",
      " 13  koi_impact_err2    6991 non-null   float64\n",
      " 14  koi_duration       6991 non-null   float64\n",
      " 15  koi_duration_err1  6991 non-null   float64\n",
      " 16  koi_duration_err2  6991 non-null   float64\n",
      " 17  koi_depth          6991 non-null   float64\n",
      " 18  koi_depth_err1     6991 non-null   float64\n",
      " 19  koi_depth_err2     6991 non-null   float64\n",
      " 20  koi_prad           6991 non-null   float64\n",
      " 21  koi_prad_err1      6991 non-null   float64\n",
      " 22  koi_prad_err2      6991 non-null   float64\n",
      " 23  koi_teq            6991 non-null   int64  \n",
      " 24  koi_insol          6991 non-null   float64\n",
      " 25  koi_insol_err1     6991 non-null   float64\n",
      " 26  koi_insol_err2     6991 non-null   float64\n",
      " 27  koi_model_snr      6991 non-null   float64\n",
      " 28  koi_tce_plnt_num   6991 non-null   int64  \n",
      " 29  koi_steff          6991 non-null   int64  \n",
      " 30  koi_steff_err1     6991 non-null   int64  \n",
      " 31  koi_steff_err2     6991 non-null   int64  \n",
      " 32  koi_slogg          6991 non-null   float64\n",
      " 33  koi_slogg_err1     6991 non-null   float64\n",
      " 34  koi_slogg_err2     6991 non-null   float64\n",
      " 35  koi_srad           6991 non-null   float64\n",
      " 36  koi_srad_err1      6991 non-null   float64\n",
      " 37  koi_srad_err2      6991 non-null   float64\n",
      " 38  ra                 6991 non-null   float64\n",
      " 39  dec                6991 non-null   float64\n",
      " 40  koi_kepmag         6991 non-null   float64\n",
      "dtypes: float64(31), int64(9), object(1)\n",
      "memory usage: 2.2+ MB\n",
      "None\n",
      "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
      "0       CONFIRMED              0              0              0              0   \n",
      "1  FALSE POSITIVE              0              1              0              0   \n",
      "2  FALSE POSITIVE              0              1              0              0   \n",
      "3       CONFIRMED              0              0              0              0   \n",
      "4       CONFIRMED              0              0              0              0   \n",
      "\n",
      "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
      "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
      "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
      "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
      "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
      "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
      "\n",
      "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
      "0          0.003520  ...             -81      4.467           0.064   \n",
      "1          0.000581  ...            -176      4.544           0.044   \n",
      "2          0.000115  ...            -174      4.564           0.053   \n",
      "3          0.001130  ...            -211      4.438           0.070   \n",
      "4          0.001900  ...            -232      4.486           0.054   \n",
      "\n",
      "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
      "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
      "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
      "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
      "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
      "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
      "\n",
      "         dec  koi_kepmag  \n",
      "0  48.141651      15.347  \n",
      "1  48.134129      15.436  \n",
      "2  48.285210      15.597  \n",
      "3  48.226200      15.509  \n",
      "4  48.224670      15.714  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "['CONFIRMED' 'FALSE POSITIVE' 'CANDIDATE']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Rename \"FALSE POSITIVE\" disposition values\r\n",
    "df.koi_disposition = df.koi_disposition.str.replace(' ','_')\r\n",
    "print(df.koi_disposition.unique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['CONFIRMED' 'FALSE_POSITIVE' 'CANDIDATE']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Select features\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Split dataframe into X and y\r\n",
    "tree_features = ['koi_fpflag_nt', 'koi_fpflag_co', 'koi_fpflag_ss', 'koi_model_snr']\r\n",
    "forest_features = ['koi_fpflag_co', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_model_snr', 'koi_prad']\r\n",
    "X = df[set(tree_features + forest_features)]\r\n",
    "y = df[\"koi_disposition\"]\r\n",
    "print(X.shape, y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6991, 5) (6991,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Split X and y into training and testing groups\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    X, y, test_size=0.3, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Display training data\r\n",
    "X_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      koi_fpflag_co  koi_model_snr  koi_fpflag_ss  koi_prad  koi_fpflag_nt\n",
       "4954              0            7.8              0      2.29              0\n",
       "4235              1           12.7              0      1.82              0\n",
       "848               0           17.9              0      2.31              0\n",
       "2874              1           43.3              1     23.81              0\n",
       "3016              0           17.4              0      1.40              0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>1</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>1</td>\n",
       "      <td>43.3</td>\n",
       "      <td>1</td>\n",
       "      <td>23.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Scale the data with MinMaxScaler\r\n",
    "X_scaler = MinMaxScaler().fit(X_train)\r\n",
    "X_train_scaled = X_scaler.transform(X_train)\r\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# One-Hot-Encode the y data\r\n",
    "\r\n",
    "# Step 1: Label-encode data set\r\n",
    "label_encoder = LabelEncoder()\r\n",
    "label_encoder.fit(y_train)\r\n",
    "encoded_y_train = label_encoder.transform(y_train)\r\n",
    "encoded_y_test = label_encoder.transform(y_test)\r\n",
    "\r\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\r\n",
    "y_train_categorical = to_categorical(encoded_y_train)\r\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print('Unique KOI Disposition Values')\r\n",
    "print(y.unique())\r\n",
    "print('-----------')\r\n",
    "print('Sample KOI Disposition Values and Encoding')\r\n",
    "print(y_test[:5])\r\n",
    "print(y_test_categorical[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unique KOI Disposition Values\n",
      "['CONFIRMED' 'FALSE_POSITIVE' 'CANDIDATE']\n",
      "-----------\n",
      "Sample KOI Disposition Values and Encoding\n",
      "4982    FALSE_POSITIVE\n",
      "4866         CANDIDATE\n",
      "2934    FALSE_POSITIVE\n",
      "5007    FALSE_POSITIVE\n",
      "3869    FALSE_POSITIVE\n",
      "Name: koi_disposition, dtype: object\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter Tuning\r\n",
    "\r\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Code was modified from sample code presented on\r\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\r\n",
    "\r\n",
    "# Function to create model, required for KerasClassifier\r\n",
    "def create_model(neurons=5):\r\n",
    "\t# create model\r\n",
    "\tmodel = Sequential()\r\n",
    "\tmodel.add(Dense(neurons, input_dim=X_train_scaled.shape[1], activation='relu'))\r\n",
    "\tmodel.add(Dropout(0.2))\r\n",
    "\tmodel.add(Dense(units=y_train_categorical.shape[1], activation='softmax'))\r\n",
    "\t# Compile model\r\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
    "\treturn model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Code was modified from sample code presented on\r\n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\r\n",
    "\r\n",
    "# Use scikit-learn to grid search the batch size and epochs\r\n",
    "\r\n",
    "# create model\r\n",
    "grid_model = KerasClassifier(build_fn=create_model, verbose=0)\r\n",
    "\r\n",
    "# define the grid search parameters\r\n",
    "batch_size = [10, 20]\r\n",
    "epochs = [100, 1000]\r\n",
    "neurons = [3, 4 , 5]\r\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs, neurons=neurons)\r\n",
    "\r\n",
    "# Apply GridSearchCV\r\n",
    "grid = GridSearchCV(estimator=grid_model, param_grid=param_grid, n_jobs=-1, cv=3)\r\n",
    "grid_result = grid.fit(X_train_scaled, y_train_categorical)\r\n",
    "\r\n",
    "# summarize results\r\n",
    "print(\"--------------------------\")\r\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
    "means = grid_result.cv_results_['mean_test_score']\r\n",
    "stds = grid_result.cv_results_['std_test_score']\r\n",
    "params = grid_result.cv_results_['params']\r\n",
    "for mean, stdev, param in zip(means, stds, params):\r\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------------\n",
      "Best: 0.894543 using {'batch_size': 20, 'epochs': 1000, 'neurons': 20}\n",
      "0.801553 (0.018024) with: {'batch_size': 10, 'epochs': 100, 'neurons': 5}\n",
      "0.821582 (0.007559) with: {'batch_size': 10, 'epochs': 100, 'neurons': 10}\n",
      "0.816881 (0.004758) with: {'batch_size': 10, 'epochs': 100, 'neurons': 15}\n",
      "0.827713 (0.002294) with: {'batch_size': 10, 'epochs': 100, 'neurons': 20}\n",
      "0.822399 (0.005039) with: {'batch_size': 10, 'epochs': 1000, 'neurons': 5}\n",
      "0.847537 (0.024228) with: {'batch_size': 10, 'epochs': 1000, 'neurons': 10}\n",
      "0.849785 (0.031933) with: {'batch_size': 10, 'epochs': 1000, 'neurons': 15}\n",
      "0.891273 (0.006797) with: {'batch_size': 10, 'epochs': 1000, 'neurons': 20}\n",
      "0.805641 (0.011514) with: {'batch_size': 20, 'epochs': 100, 'neurons': 5}\n",
      "0.819743 (0.003045) with: {'batch_size': 20, 'epochs': 100, 'neurons': 10}\n",
      "0.819743 (0.007947) with: {'batch_size': 20, 'epochs': 100, 'neurons': 15}\n",
      "0.822195 (0.005902) with: {'batch_size': 20, 'epochs': 100, 'neurons': 20}\n",
      "0.847946 (0.030484) with: {'batch_size': 20, 'epochs': 1000, 'neurons': 5}\n",
      "0.846515 (0.028382) with: {'batch_size': 20, 'epochs': 1000, 'neurons': 10}\n",
      "0.841815 (0.019549) with: {'batch_size': 20, 'epochs': 1000, 'neurons': 15}\n",
      "0.894543 (0.005642) with: {'batch_size': 20, 'epochs': 1000, 'neurons': 20}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create and Train the Model - Neural Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Create model\r\n",
    "nn_model = Sequential()\r\n",
    "\r\n",
    "# Define first layer\r\n",
    "nn_model.add(Dense(units=5,\r\n",
    "                activation='relu', input_dim=X_train_scaled.shape[1]))\r\n",
    "\r\n",
    "# Define output layer\r\n",
    "nn_model.add(Dense(units=y_train_categorical.shape[1], activation='softmax'))    \r\n",
    "\r\n",
    "# Review Model\r\n",
    "print(nn_model.summary())\r\n",
    "\r\n",
    "# Compile Model\r\n",
    "nn_model.compile(optimizer='adam',\r\n",
    "              loss='categorical_crossentropy',\r\n",
    "              metrics=['accuracy'])\r\n",
    "\r\n",
    "# Train model\r\n",
    "nn_model.fit(\r\n",
    "    X_train_scaled,\r\n",
    "    y_train_categorical,\r\n",
    "    epochs=1000,\r\n",
    "    batch_size=10,\r\n",
    "    shuffle=True,\r\n",
    "    verbose=0\r\n",
    ")\r\n",
    "\r\n",
    "# Evaluate the model using the testing data\r\n",
    "model_loss, model_accuracy = nn_model.evaluate(\r\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\r\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 63        \n",
      "=================================================================\n",
      "Total params: 483\n",
      "Trainable params: 483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "66/66 - 0s - loss: 0.2576 - accuracy: 0.8942\n",
      "Loss: 0.25760945677757263, Accuracy: 0.894184947013855\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Option 3: Model Results when using selected features from Decision Tree and Random Forest Classifiers\r\n",
    "* Grid Definition: \r\n",
    "    * batch_size = [10, 20]\r\n",
    "    * epochs = [100, 1000]\r\n",
    "    * neurons = [3, 4 , 5]\r\n",
    "* Grid Best Result: \r\n",
    "* Tuned Model Results: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save the Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Save the model results\r\n",
    "nn_model.save(\"./f_neuralNetwork_tree_Features_model.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Discussion\r\n",
    "\r\n",
    "The model score using the neural network method is one of the best for predicting exoplanet observations. However, the hyperparameter tuning is very slow."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('PythonDataV2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "interpreter": {
   "hash": "7145387fd502c2a792381ef9ef58718f99f5f6cce2c67dc36e296264320f59ee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}